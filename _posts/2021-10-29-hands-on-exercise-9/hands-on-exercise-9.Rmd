---
title: "Hands-on Exercise 9"
description: |
  In this hands-on exercise, I learn how to calibrate geographicailly weighted regression models by using GWmodel package of R.
author:
  - name: Ngah Xin Yan
    url: https://github.com/nxinyan/
date: 10-29-2021
output:
  distill::distill_article:
    self_contained: false
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, 
                      eval = TRUE,
                      message = FALSE,
                      warning = FALSE,
                      fig.retina = 3)
```

# Overview

Geographically weighted regression (GWR) is a spatial statistical technique that takes non-stationary variables into consideration (e.g., climate; demographic factors; physical environment characteristics) and models the local relationships between these independent variables and an outcome of interest (also known as dependent variable). In this hands-on exercise, you will learn how to build hedonic pricing models by using GWR methods. The dependent variable is the resale prices of condominium in 2015. The independent variables are divided into either structural and locational.

## Data Used

The following datasets were used:

- URA Master Plan subzone boundary in shapefile format (i.e. MP14_SUBZONE_WEB_PL)
- condo_resale_2015 in csv format (i.e. condo_resale_2015.csv)

## Installing and Loading the R packages

- [**olsrr**](https://olsrr.rsquaredacademy.com/index.html): for building OLS and performing diagnostics tests

- [**GWmodel**](https://cran.r-project.org/web/packages/GWmodel/index.html): to calibrate geographical weighted family of models

- [**corrplot**](https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html): for multivariate data visualisation and analysis

- **sf**: spatial data handling

- **tidyverse**: attribute data handling

- **tmap**: choropleth mapping

```{r}
packages = c('olsrr', 'corrplot', 'ggpubr', 'sf', 'spdep', 'GWmodel', 'tmap', 'tidyverse')
for (p in packages){
  if(!require(p, character.only = T)){
    install.packages(p)
  }
  library(p,character.only = T)
}
```

## Note on GWmodel

[**GWmodel**](https://cran.r-project.org/web/packages/GWmodel/index.html) package provides a collection of localised spatial statistical methods:

- GW summary statistics
- GW principal components analysis
- GW discriminant analysis
- various forms of GW regression (provided in basic or robust (outlier resistant) forms)

Commonly, outputs or parameters of the GWmodel are mapped to provide a useful exploratory tool, which can often precede (and direct) a more traditional or sophisticated statistical analysis.

# Geospatial Data Wrangling

## Importing geospatial data

*MP14_SUBZONE_WEB_PL* is the geospatial data used. It is in ESRI shapefile format.The shapefile consists of URA Master Plan 2014’s planning subzone boundaries. Polygon features are used to represent these geographic boundaries. The GIS data is in svy21 projected coordinates systems.

```{r}
mpsz = st_read(dsn = "data/geospatial", layer = "MP14_SUBZONE_WEB_PL")
```

Assigned the MP14_SUBZONE_WEB_PL shapefile to *mpsz*. It is a simple feature object. The geometry type is multipolygon. it is also important to note that mpsz simple feature object does not have EPSG information.

## Updating CRS information

```{r}
mpsz_svy21 <- st_transform(mpsz, 3414)
```

Verifying the projection of the newly transformed *mpsz_svy21* by using st_crs() of sf package

```{r}
st_crs(mpsz_svy21)
```

Reveal extent of mpsz_svy21 using *st_bbox()* of sf package.

```{r}
st_bbox(mpsz_svy21)
```

# Aspatial Data Wrangling

## Importing the aspatial data

The *condo_resale_2015* is in csv file format. The codes chunk below uses *read_csv()* function of **readr** package to import *condo_resale_2015* into R as a tibble data frame called *condo_resale*.

```{r}
condo_resale = read_csv("data/aspatial/Condo_resale_2015.csv")
```

After importing the data file into R, it is important to examine if the data file has been imported correctly.

Learning more about the associated attribute information in the data frame. 

```{r}
glimpse(condo_resale)
```

To see the data in XCOORD column 

```{r}
head(condo_resale$LONGITUDE) 
```

To see the data in YCOORD column

```{r}
head(condo_resale$LATITUDE) 
```

```{r}
summary(condo_resale)
```

## Converting aspatial data frame into a sf object

The *condo resale* data frame is aspatial. Converting *condo_resale* data frame into a simple feature data frame by using *st_as_sf()*.

*st_transform()*  is also used to convert the coordinates from wgs84 to svy21

```{r}
condo_resale.sf <- st_as_sf(condo_resale,
                            coords = c("LONGITUDE", "LATITUDE"),
                            crs=4326) %>%
  st_transform(crs=3414)
head(condo_resale.sf)
```

# Exploratory Data Analysis

## EDA using statistical graphics

Plotting the distribution of SELLING_PRICE by using appropriate Exploratory Data Analysis (EDA)

```{r}
ggplot(data=condo_resale.sf, aes(x=`SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

More condominium units were transacted at a relative lower price as it is a right skewed distribution.

Statistically, the skewed dsitribution can be normalised by using log transformation. It is performed using mutate() of dplyr package.

```{r}
condo_resale.sf <- condo_resale.sf %>%
  mutate(`LOG_SELLING_PRICE` = log(SELLING_PRICE))
```

Plot the ***LOG_SELLING_PRICE***

```{r}
ggplot(data=condo_resale.sf, aes(x=`LOG_SELLING_PRICE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")
```

The distribution of the histogram is less skewed after the transformation.

## Multiple Histogram Plots distribution of variables

Drawing small multiple histograms by using ggarrange() of ggpubr package.

```{r}
AREA_SQM <- ggplot(data=condo_resale.sf, aes(x= `AREA_SQM`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

AGE <- ggplot(data=condo_resale.sf, aes(x= `AGE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CBD <- ggplot(data=condo_resale.sf, aes(x= `PROX_CBD`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_CHILDCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_CHILDCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_ELDERLYCARE <- ggplot(data=condo_resale.sf, aes(x= `PROX_ELDERLYCARE`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_URA_GROWTH_AREA <- ggplot(data=condo_resale.sf, aes(x= `PROX_URA_GROWTH_AREA`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_HAWKER_MARKET <- ggplot(data=condo_resale.sf, aes(x= `PROX_HAWKER_MARKET`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_KINDERGARTEN <- ggplot(data=condo_resale.sf, aes(x= `PROX_KINDERGARTEN`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_MRT <- ggplot(data=condo_resale.sf, aes(x= `PROX_MRT`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PARK <- ggplot(data=condo_resale.sf, aes(x= `PROX_PARK`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

PROX_TOP_PRIMARY_SCH <- ggplot(data=condo_resale.sf, aes(x= `PROX_TOP_PRIMARY_SCH`)) +
  geom_histogram(bins=20, color="black", fill="light blue")

ggarrange(AREA_SQM, AGE, PROX_CBD, PROX_CHILDCARE, PROX_ELDERLYCARE, PROX_URA_GROWTH_AREA, PROX_HAWKER_MARKET, PROX_KINDERGARTEN, PROX_MRT, PROX_PARK, PROX_PRIMARY_SCH, PROX_TOP_PRIMARY_SCH,  ncol = 3, nrow = 4)
```

## Drawing Statistical Point Map

Revealing the geospatial distribution condominium resale prices in Singapore.

Using interactive mode

```{r}
tmap_mode("view")
```

Create an interactive point symbol map

```{r}
tmap_options(check.and.fix = TRUE)
tm_shape(mpsz_svy21)+
  tm_polygons() +
tm_shape(condo_resale.sf) +  
  tm_dots(col = "SELLING_PRICE",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
```

*set.zoom.limits* argument of *tm_view()* sets the minimum and maximum zoom level to 11 and 14 respectively.

Turn R display into plot mode

```{r}
tmap_mode("plot")
```

# Hedonic Pricing Modelling in R

Learning how to building hedonic pricing models for condominium resale units using *lm()* of R base.

## Simple Linear Regression Method

Building a simple linear regression model by using *SELLING_PRICE* as the dependent variable and *AREA_SQM* as the independent variable.

```{r}
condo.slr <- lm(formula=SELLING_PRICE ~ AREA_SQM, data = condo_resale.sf)
```

*lm()* returns an object of class “lm” or for multiple responses of class c(“mlm”, “lm”).

The functions *summary()* and *anova()* can be used to obtain and print a summary and analysis of variance table of the results. The generic accessor functions coefficients, effects, fitted.values and residuals extract various useful features of the value returned by **lm**.

```{r}
summary(condo.slr)
```

The output report reveals that the SELLING_PRICE can be explained by using the formula:

$$
y = -258121.1 + 14719x1
$$
From the summary above, the R-squared value is 0.4518. This means that the simple regression model built is able to explain about 45% of the resale prices.

Since our p-value is much smaller than 0.0001, we will reject the null hypothesis that the mean is a good estimator of `SELLING_PRICE`. This allows us to infer that the simple linear regression model above is a good estimator of `SELLING_PRICE`.

The **Coefficients:** section of the report reveals that the p-values of both the estimates of the `Intercept` and `ARA_SQM` are smaller than 0.001. Within this context, the null hypothesis of the B0 and B1 are equal to 0 will be rejected. As such, we can infer that B0 and B1 are good parameter estimates.

Visualising the best fit curve on a scatterplot, by incorporating *lm()* as a method function in ggplot's geometry

```{r}
ggplot(data=condo_resale.sf,  
       aes(x=`AREA_SQM`, y=`SELLING_PRICE`)) +
  geom_point() +
  geom_smooth(method = lm)
```

The figure shows that there are a few statistical outliers with relatively high selling prices.

## Multiple Linear Regression Method

### Visualising the relationships of the independent variables

When building a multiple regression model, the independent variables used should not be high correlated to eahc other. If highly correlated independent variables are used in building a regression model, the quality of the model will be compromised. This phenomena is known as ***multicollinearity*** in statistics.

Correlation matrix is commonly used to visualise the relationships between the independent variables. There are many packages support the display of a correlation matrix, including *pairs()* of R. In this section, the **corrplot** package will be used.

Plotting a scatterplot matrix of the relationship between the independent variables in ***condo_resale*** data.frame.

```{r}
corrplot(cor(condo_resale[, 5:23]), diag = FALSE, order = "AOE",
         tl.pos = "td", tl.cex = 0.5, method = "number", type = "upper")
```

Matrix reorder is very important for mining the hidden structure and patter in the matrix. There are four methods in corrplot (parameter order), named “AOE”, “FPC”, “hclust”, “alphabet”. In the code chunk above, AOE order is used. It orders the variables by using the **angular order of the eigenvectors method** suggested by Michael Friendly.

From the scatterplot matrix, it is clear that ***Freehold*** is highly correlated to ***LEASE_99YEAR***. In view of this, it is wiser to only include either one of them in the subsequent model building. As a result, ***LEASE_99YEAR*** is excluded in the subsequent model building.

### Building a hedonic pricing model using multiple linear regression method

Using lm() to calibrate the multiple linear regression model.

```{r}
condo.mlr <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE  + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_HAWKER_MARKET  + PROX_KINDERGARTEN  + PROX_MRT  + PROX_PARK  + PROX_PRIMARY_SCH + PROX_TOP_PRIMARY_SCH + PROX_SHOPPING_MALL  + PROX_SUPERMARKET + PROX_BUS_STOP  + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data=condo_resale.sf)
summary(condo.mlr)
```

From the report above, it is clear that not all the independent variables are statistically significant. The model will be revised by removing those variables which are not statistically significant.

Calibrating the revised model 

```{r}
condo.mlr1 <- lm(formula = SELLING_PRICE ~ AREA_SQM + AGE  + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK  + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL  + PROX_BUS_STOP  + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data=condo_resale.sf)
ols_regress(condo.mlr1)
```

### Checking for multicolinearity

In this section, a new R package specially programmed for performing OLS regression is introduced. It is called **olsrr**. It provides a collection of very useful methods for building better multiple linear regression models:

- comprehensive regression output
- residual diagnostics
- measures of influence
- heteroskedasticity tests
- collinearity diagnostics
- model fit assessment
- variable contribution assessment
- variable selection procedures

*ols_vif_tol()* of **olsrr** package is used to test if there are sign of multicollinearity

```{r}
ols_vif_tol(condo.mlr1)
```

Since the VIF of the independent variables are less than 10. We can safely conclude that there are no sign of multicollinearity among the independent variables.

### Test for Non-Linearity

In multiple linear regression, it is important for us to test the assumption that linearity and additivity of the relationship between dependent and independent variables.

*ols_plot_resid_fit()* of **olsrr** package is used to perform linearity assumption test.

```{r}
ols_plot_resid_fit(condo.mlr1)
```

The figure shows that most of the data points are scattered around the 0 line, hence we can safely conclude that the relationships between the dependent variable and independent variables are linear.

### Test for Normality Assumption

*ols_plot_resid_hist()* of **olsrr** package to perform normality assumption test.

```{r}
ols_plot_resid_hist(condo.mlr1)
```

The figure reveals that the residual of the multiple linear regression model (i.e. condo.mlr1) is resemble **normal distribution**.

*ols_test_normality()* of **olsrr** package can be used if formal statistical test methods are preferred.

```{r}
ols_test_normality(condo.mlr1)
```

The summary table above reveals that the p-values of the four tests are way smaller than the alpha value of 0.05. Hence we will reject the null hypothesis that the residual is NOT resemble normal distribution. 

### Testing for Spatial Autocorrelation

The building of the hedonic model will use geographically referenced attributes, hence it is also important to visualise the residual of the hedonic pricing model.

In order to perform spatial autocorrelation test, we need to convert **condo_resale.sf**  simple feature into a SpatialPointsDataFrame.

First, export the residual of the hedonic pricing model and save it as a data frame.

```{r}
mlr.output <- as.data.frame(condo.mlr1$residuals)
```

Next, join the newly created data frame with **condo_resale.sf** object.

```{r}
condo_resale.res.sf <- cbind(condo_resale.sf, 
                        condo.mlr1$residuals) %>%
rename(`MLR_RES` = `condo.mlr1.residuals`)
```

Next, convert **condo_resale.res.sf** simple feature object into a SpatialPointsDataFrame because spdep package can only process sp conformed spatial data objects.

```{r}
condo_resale.sp <- as_Spatial(condo_resale.res.sf)
condo_resale.sp
```

Next, the **tmap** package to display the distribution of the residuals on an interactive map.

```{r}
tmap_mode("view")
tm_shape(mpsz_svy21)+
  tm_polygons(alpha = 0.4) +
tm_shape(condo_resale.res.sf) +  
  tm_dots(col = "MLR_RES",
          alpha = 0.6,
          style="quantile") +
  tm_view(set.zoom.limits = c(11,14))
tmap_mode("plot")
```

The figure above shows that there is sign of spatial autocorrelation.

To proof that our observation is indeed true, the Moran’s I test will be performed

First, compute the distance-based weight matrix by using *dnearneigh()* function of **spdep**.

```{r}
nb <- dnearneigh(coordinates(condo_resale.sp), 0, 1500, longlat = FALSE)
summary(nb)
```

Next, *nb2listw()* of **spdep** packge will be used to convert the output neighbours lists (i.e. nb) into a spatial weights.

```{r}
nb_lw <- nb2listw(nb, style = 'W')
summary(nb_lw)
```

Next, *lm.morantest()* of **spdep** package will be used to perform Moran’s I test for residual spatial autocorrelation.

```{r}
lm.morantest(condo.mlr1, nb_lw)
```

The Global Moran’s I test for residual spatial autocorrelation shows that it’s p-value is less than 0.00000000000000022 which is less than the alpha value of 0.05. Hence, we will reject the null hypothesis that the residuals are randomly distributed.

Since the Observed Global Moran I = 0.1424418 which is greater than 0, we can infer than the residuals resemble cluster distribution.

# Building Hedonic Pricing Models using GWmodel

In this section, you are going to learn how to modelling hedonic pricing using both the fixed and adaptive bandwidth schemes

## Building Fixed Bandwidth GWR Model

### Computing fixed bandwith

*bw.gwr()* of **GWModel** package is used to determine the optimal fixed bandwidth to use in the model. 

Notice that the argument ***adaptive*** is set to **FALSE** indicates that we are interested to compute the fixed bandwidth.

There are two possible approaches can be used to determine the stopping rule, they are: CV cross-validation approach and AIC corrected (AICc) approach. We define the stopping rule using **approach** agreement.

```{r}
bw.fixed <- bw.gwr(formula = SELLING_PRICE ~ AREA_SQM + AGE  + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK  + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL  + PROX_BUS_STOP  + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data=condo_resale.sp, approach="CV", kernel="gaussian", adaptive=FALSE, longlat=FALSE)
```

The result shows that the recommended bandwidth is 971.3398 metres. (Quiz: Do you know why it is in metre? The projection coordinates system SVY21 is in metres, thus results are in metres)

### GWModel method - fixed bandwith

Calibrating the gwr model using fixed bandwidth and gaussian kernel

```{r}
gwr.fixed <- gwr.basic(formula = SELLING_PRICE ~ AREA_SQM + AGE  + PROX_CBD + PROX_CHILDCARE + PROX_ELDERLYCARE  + PROX_URA_GROWTH_AREA + PROX_MRT  + PROX_PARK  + PROX_PRIMARY_SCH + PROX_SHOPPING_MALL  + PROX_BUS_STOP  + NO_Of_UNITS + FAMILY_FRIENDLY + FREEHOLD, data=condo_resale.sp, bw=bw.fixed, kernel = 'gaussian', longlat = FALSE)
```

The output is saved in a list of class “gwrm”. 
Display the model output.

```{r}
gwr.fixed
```

The report shows that the adjusted r-square of the gwr is 0.8430 which is significantly better than the globle multiple linear regression model of 0.6472.

## Building Adaptive Bandwidth GWR Model

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```

```{r}

```
